---
title: 'Entrega: Tarea 2'
author: "Laura Basalo Tur, Camila Pérez Arévalo, Josep Roman Cardell"
output:
  pdf_document: default
  html_document: default
---


```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.align="center", echo=TRUE, warning=FALSE, message=FALSE,autodep = TRUE,cache=TRUE)
library(knitr)
library(printr)
library(igraph)
```

We shall consider again the undirected Facebook friendship network considered in the last handout. The links in this network are contained in the file **facebook_sample_anon.txt**. Download it on your computer and upload it to R as a dataframe. Define an undirected graph with this list of edges.

```{r cargarDatos}
#Cargamos los datos del fichero .txt en un dataframe
dataframe = read.table("data/facebook_sample_anon.txt",
                       header = FALSE, 
                       col.names = c("nodeA", "nodeB"),
                       sep = " ")

#Generamos el grafo no dirigido desde los datos del dataframe
undirected_graph = graph_from_data_frame(dataframe, directed=F)

```


&nbsp;



**1) It has been observed in many networks an association between "centrality" and "lethality," defined as the fatal disconnection of the network when nodes are removed. Let's study this association on this network.**

*a)* Repeat 1000 times the procedure of removing a random 0.1% of its set of nodes, and compute the average number of connected components of the resulting networks and the average fraction of the network represented by the largest component. Use **set.seed** to make your results reproducible.


```{r apartadoA}

#Indicamos la semilla a utilizar para que no cambien los resultados:
set.seed(4321)

#Número de repeticiones
n = 1000

compute_graph_random = function(g, n, perc){
  
  #Inicializamos dos listas vacías donde se guardarán los datos a calcular
  avrg_connected = c()
  avrg_largest_component = c()
  #Calculamos el porcentaje de nodos a eliminar
  perc = (0.1/100)*vcount(g)
  
  for(i in 1:n+1){
    #Obtenemos el 0.1% de vértices aleatorios a eliminar
    v_to_delete = sample(V(g), perc) 
    g = delete_vertices(g, v_to_delete)
    #Obtenemos información de los componentes del grafo
    components = components(g)
    #Guardamos el número de componentes conexos
    avrg_connected = c(avrg_connected, components$no)
    #Guardamos la fracción del componente conexo más grande
    avrg_largest_component = c(avrg_largest_component, max(components$csize)/vcount(g)) 
  }

  result = list("Average number of connected components" = mean(avrg_connected),
                "Average fraction by largest component" = mean(avrg_largest_component))
  return(result)
}

#Ejecutamos la función del cálculo con el grafo no dirigido
compute_graph_random(undirected_graph, n, perc)

```
COMENTARIOS



&nbsp;


*b)* Now, compute the number of connected components and the fraction represented by the largest component of the networks obtained after removing the most central 0.1% of nodes, for the following centrality indices (of course, if the most central 0.1% of nodes for two indices are the same set of nodes, you need not waste your time considering twice the same network): *degree*; *closeness*; *betweenness*; *page.rank*. (**Hint**: It might be convenient to define first a function that removes a given set of nodes of this graph and computes the number of connected components and the fraction represented by the largest component of the resulting network; then you will only need to apply it to the required different sets of most central nodes.) Is it what you expected? 



```{r apartadoB_Degree, eval=FALSE}
order_by_degree = order(centr_degree(undirected_graph)$res, decreasing = TRUE)
v_to_delete = order_by_degree[1:perc]
```

```{r apartadoB_Degree_Full, echo = FALSE}
compute_graph_degree = function(g, n, perc){
  
  #Inicializamos dos listas vacías donde se guardarán los datos a calcular
  avrg_connected = c()
  avrg_largest_component = c()
  #Calculamos el porcentaje de nodos a eliminar
  perc = (0.1/100)*vcount(g)
  
  for(i in 1:n+1){
    #Obtenemos el 0.1% de vértices a eliminar por grado
    order_by_degree = order(centr_degree(g)$res, decreasing = TRUE)
    v_to_delete = order_by_degree[1:perc]
    g = delete_vertices(g, v_to_delete)
    #Obtenemos información de los componentes del grafo
    components = components(g)
    #Guardamos el número de componentes conexos
    avrg_connected = c(avrg_connected, components$no)
    #Guardamos la fracción del componente conexo más grande
    avrg_largest_component = c(avrg_largest_component, max(components$csize)/vcount(g)) 
  }

  result = list("Average number of connected components" = mean(avrg_connected),
                "Average fraction by largest component" = mean(avrg_largest_component))
  return(result)
}

#Ejecutamos la función del cálculo con el grafo no dirigido
compute_graph_degree(undirected_graph, n, perc)
```


```{r apartadoB_Closeness, eval=FALSE}
order_by_clos = order(centr_clo(undirected_graph)$res, decreasing = TRUE)
v_to_delete = order_by_clos[1:perc]
```

```{r apartadoB_Closeness_Full, echo = FALSE, eval = FALSE}
compute_graph_closeness = function(g, n, perc){
  
  #Inicializamos dos listas vacías donde se guardarán los datos a calcular
  avrg_connected = c()
  avrg_largest_component = c()
  #Calculamos el porcentaje de nodos a eliminar
  perc = (0.1/100)*vcount(g)
  
  subgraph = g
  
  for(i in 1:n+1){
    #Obtenemos el 0.1% de vértices a eliminar por cercanía
    order_by_clos = order(centr_clo(subgraph)$res, decreasing = TRUE)
    v_to_delete = order_by_clos[1:perc]
    g = delete_vertices(g, v_to_delete)
    #names = V(g)[v_to_delete]$names
    #g = delete_vertices(g, V(g)$names == names)
    #Obtenemos información de los componentes del grafo
    components = components(g)
    #Guardamos el número de componentes conexos
    avrg_connected = c(avrg_connected, components$no)
    #Guardamos la fracción del componente conexo más grande
    avrg_largest_component = c(avrg_largest_component, max(components$csize)/vcount(g))
    
    #Obtenemos subgrafo del componente más grande para calcular closeness sobre este componente
    larg_component = which.max(components$csize)
    subgraph = induced_subgraph(g, which(components$membership == larg_component))
  }

  result = list("Average number of connected components" = mean(avrg_connected),
                "Average fraction by largest component" = mean(avrg_largest_component))
  return(result)
}

#Ejecutamos la función del cálculo con el grafo no dirigido
compute_graph_closeness(undirected_graph, n, perc)
```


```{r apartadoB_Betweenness, eval=FALSE}
order_by_betwennes = order(centr_betw(undirected_graph)$res, decreasing = TRUE)
v_to_delete = order_by_betwennes[1:perc]
```

```{r apartadoB_Betwennes_Full, echo = FALSE}
compute_graph_betwennes = function(g, n, perc){
  
  #Inicializamos dos listas vacías donde se guardarán los datos a calcular
  avrg_connected = c()
  avrg_largest_component = c()
  #Calculamos el porcentaje de nodos a eliminar
  perc = (0.1/100)*vcount(g)
  
  for(i in 1:n+1){
    #Obtenemos el 0.1% de vértices a eliminar según intermediación
    order_by_betwennes = order(centr_betw(g)$res, decreasing = TRUE)
    v_to_delete = order_by_betwennes[1:perc]
    g = delete_vertices(g, v_to_delete)
    #Obtenemos información de los componentes del grafo
    components = components(g)
    #Guardamos el número de componentes conexos
    avrg_connected = c(avrg_connected, components$no)
    #Guardamos la fracción del componente conexo más grande
    avrg_largest_component = c(avrg_largest_component, max(components$csize)/vcount(g)) 
  }

  result = list("Average number of connected components" = mean(avrg_connected),
                "Average fraction by largest component" = mean(avrg_largest_component))
  return(result)
}

#Ejecutamos la función del cálculo con el grafo no dirigido
compute_graph_betwennes(undirected_graph, n, perc)
```


```{r apartadoB_PageRank, eval=FALSE}
page_rank_result = page_rank(undirected_graph, directed = FALSE, algo = "power")
order_by_pagerank = order(page_rank_result$vector, decreasing = TRUE)
v_to_delete = order_by_pagerank[1:perc]
```

```{r apartadoB_PageRank_Full, echo = FALSE}
compute_graph_pagerank = function(g, n, perc){
  
  #Inicializamos dos listas vacías donde se guardarán los datos a calcular
  avrg_connected = c()
  avrg_largest_component = c()
  #Calculamos el porcentaje de nodos a eliminar
  perc = (0.1/100)*vcount(g)
  
  for(i in 1:n+1){
    #Obtenemos el 0.1% de vértices a eliminar según intermediación
    page_rank_result = page_rank(g, directed = FALSE, algo = "power")
    order_by_pagerank = order(page_rank_result$vector, decreasing = TRUE)
    v_to_delete = order_by_pagerank[1:perc]
    g = delete_vertices(g, v_to_delete)
    #Obtenemos información de los componentes del grafo
    components = components(g)
    #Guardamos el número de componentes conexos
    avrg_connected = c(avrg_connected, components$no)
    #Guardamos la fracción del componente conexo más grande
    avrg_largest_component = c(avrg_largest_component, max(components$csize)/vcount(g)) 
  }

  result = list("Average number of connected components" = mean(avrg_connected),
                "Average fraction by largest component" = mean(avrg_largest_component))
  return(result)
}

#Ejecutamos la función del cálculo con el grafo no dirigido
compute_graph_pagerank(undirected_graph, n, perc)
```


Sí, esperabamos que la fracción del componente más largo, en el apartado b, fuese menor que en el anterior apartado ya que, en este caso se eliminan aquellos vértices que cuentan con un mayor grado. Es decir, se eliminan los vértices que cuentan con el mayor nombre de aristas de todo el grafo, por lo que sería más probable que el grafo se divida en más componentes y, como resultado, el tamaño del componente más largo se vea disminuido.

A la hora de realizar el closeness nos aparecia el siguiente error: ***At centrality.c:2784 :closeness centrality is not well-defined for disconnected graphs***, lo que sucede es que esta función da error una vez existe la división de grafos. Por este motivo hemos aplicado una restricción en la cual por cada iteración
elimine 4 vértices de el componente más largo. De esta manera se ha podido ejecutar el código sin que nos apareciese este error pero llega un momento en el cual
los componentes son de tamaño 2 y 1 por lo que closeness deja de ejecutarse.


&nbsp;


**2)** Now, consider the same graph as a directed one, and find the hubs and authorities scores. Compare with the page rank score. 

```{r ejercicio2, results="hide"}

#Generamos el grafo dirigido desde los datos del dataframe
directed_graph = graph_from_data_frame(dataframe, directed=T)

#Hub/Authorities
hub_score = hub_score(directed_graph)
authority_score = authority_score(directed_graph)

#PageRank
page_rank(directed_graph, directed = TRUE, algo = "power")

```

